{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ac622b7-eea9-4cdc-a5a6-915e9b45aa57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Polars V: 1.35.2\n",
      "Ruta al CSV: /home/ubuntu-t430/Desktop/gcp-logistics-pipeline/01_data/rutas_expanded.csv\n"
     ]
    }
   ],
   "source": [
    "# Celda 1: Importar\n",
    "import polars as pl\n",
    "import os\n",
    "print(f\"Polars V: {pl.__version__}\")\n",
    "\n",
    "# Definir rutas\n",
    "BASE_DIR = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "RAW_DATA_PATH = os.path.join(BASE_DIR, '01_data', 'rutas_expanded.csv')\n",
    "print(f\"Ruta al CSV: {RAW_DATA_PATH}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1739a129-7dcd-4172-91e7-5634b90b798c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos crudos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_17611/3880500775.py:5: DeprecationWarning: the argument `dtypes` for `read_csv` is deprecated. It was renamed to `schema_overrides` in version 0.20.31.\n",
      "  df_raw = pl.read_csv(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados: (246836, 35)\n",
      "--- Tipo de dato 'date' (debería ser String) ---\n",
      "String\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 35)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>route_id</th><th>date</th><th>weekday</th><th>week_number</th><th>driver_id</th><th>origin_barrio</th><th>lat_origin</th><th>lon_origin</th><th>barrios_recorridos</th><th>tipo_vehiculo</th><th>vehicle_capacity_m3</th><th>volumen_cargado_m3</th><th>carga_pct</th><th>n_paradas</th><th>n_paquetes</th><th>cliente_top_count</th><th>km_total</th><th>desviacion_km</th><th>velocidad_media_kmh</th><th>duracion_min</th><th>tiempo_conduccion_min</th><th>tiempo_paradas_min</th><th>tiempo_espera_deposito_min</th><th>tiempo_carga_min</th><th>n_incidentes</th><th>motivo_incidente</th><th>paquetes_no_entregados</th><th>porcentaje_entregas_exitosas</th><th>prioridad</th><th>entregas_retrasadas</th><th>clima</th><th>turno</th><th>estado_ruta</th><th>notas_logisticas</th><th>costo_est_operativo</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>f64</td><td>f64</td><td>str</td><td>str</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>str</td><td>i64</td><td>f64</td><td>str</td><td>i64</td><td>str</td><td>str</td><td>str</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>2000</td><td>&quot;2025-01-27 00:00:00&quot;</td><td>0</td><td>4</td><td>3</td><td>&quot;La Plata&quot;</td><td>-34.922486</td><td>-57.95277</td><td>&quot;La Plata; Tolosa&quot;</td><td>&quot;Furgoneta&quot;</td><td>8</td><td>7.84</td><td>98.0</td><td>71</td><td>81</td><td>6</td><td>24.6</td><td>0.07</td><td>17.57</td><td>224</td><td>84</td><td>130</td><td>10</td><td>16</td><td>1</td><td>&quot;Cliente ausente&quot;</td><td>1</td><td>98.77</td><td>&quot;media&quot;</td><td>1</td><td>&quot;Nublado&quot;</td><td>&quot;mañana&quot;</td><td>&quot;con_incidente&quot;</td><td>&quot;Devolver a depósito&quot;</td><td>29.01</td></tr><tr><td>2001</td><td>&quot;2025-03-25 00:00:00&quot;</td><td>1</td><td>12</td><td>1</td><td>&quot;Abasto&quot;</td><td>-34.820862</td><td>-57.922538</td><td>&quot;Abasto; Villa Elisa; City Bell&quot;</td><td>&quot;Camioneta&quot;</td><td>13</td><td>4.41</td><td>33.9</td><td>85</td><td>102</td><td>7</td><td>18.7</td><td>0.99</td><td>13.68</td><td>241</td><td>82</td><td>159</td><td>2</td><td>32</td><td>0</td><td>null</td><td>0</td><td>100.0</td><td>&quot;alta&quot;</td><td>0</td><td>&quot;Despejado&quot;</td><td>&quot;mañana&quot;</td><td>&quot;completa_ok&quot;</td><td>null</td><td>30.33</td></tr><tr><td>2002</td><td>&quot;2025-01-11 00:00:00&quot;</td><td>5</td><td>1</td><td>3</td><td>&quot;Abasto&quot;</td><td>-34.817327</td><td>-57.916802</td><td>&quot;Abasto; Lisandro Olmos&quot;</td><td>&quot;Camioneta&quot;</td><td>13</td><td>6.04</td><td>46.5</td><td>88</td><td>101</td><td>8</td><td>29.4</td><td>0.64</td><td>19.6</td><td>254</td><td>90</td><td>164</td><td>9</td><td>34</td><td>0</td><td>null</td><td>0</td><td>100.0</td><td>&quot;baja&quot;</td><td>0</td><td>&quot;Despejado&quot;</td><td>&quot;mañana&quot;</td><td>&quot;completa_ok&quot;</td><td>null</td><td>33.1</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 35)\n",
       "┌──────────┬────────────┬─────────┬────────────┬───┬────────┬────────────┬────────────┬────────────┐\n",
       "│ route_id ┆ date       ┆ weekday ┆ week_numbe ┆ … ┆ turno  ┆ estado_rut ┆ notas_logi ┆ costo_est_ │\n",
       "│ ---      ┆ ---        ┆ ---     ┆ r          ┆   ┆ ---    ┆ a          ┆ sticas     ┆ operativo  │\n",
       "│ i64      ┆ str        ┆ i64     ┆ ---        ┆   ┆ str    ┆ ---        ┆ ---        ┆ ---        │\n",
       "│          ┆            ┆         ┆ i64        ┆   ┆        ┆ str        ┆ str        ┆ f64        │\n",
       "╞══════════╪════════════╪═════════╪════════════╪═══╪════════╪════════════╪════════════╪════════════╡\n",
       "│ 2000     ┆ 2025-01-27 ┆ 0       ┆ 4          ┆ … ┆ mañana ┆ con_incide ┆ Devolver a ┆ 29.01      │\n",
       "│          ┆ 00:00:00   ┆         ┆            ┆   ┆        ┆ nte        ┆ depósito   ┆            │\n",
       "│ 2001     ┆ 2025-03-25 ┆ 1       ┆ 12         ┆ … ┆ mañana ┆ completa_o ┆ null       ┆ 30.33      │\n",
       "│          ┆ 00:00:00   ┆         ┆            ┆   ┆        ┆ k          ┆            ┆            │\n",
       "│ 2002     ┆ 2025-01-11 ┆ 5       ┆ 1          ┆ … ┆ mañana ┆ completa_o ┆ null       ┆ 33.1       │\n",
       "│          ┆ 00:00:00   ┆         ┆            ┆   ┆        ┆ k          ┆            ┆            │\n",
       "└──────────┴────────────┴─────────┴────────────┴───┴────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Celda 2 (MODIFICADA)\n",
    "print(\"Cargando datos crudos...\")\n",
    "\n",
    "# ¡CAMBIO CLAVE! Usamos 'dtypes' para forzar 'date' a ser texto\n",
    "df_raw = pl.read_csv(\n",
    "    RAW_DATA_PATH,\n",
    "    dtypes={\"date\": pl.String} \n",
    ")\n",
    "\n",
    "print(f\"Datos cargados: {df_raw.shape}\")\n",
    "print(\"--- Tipo de dato 'date' (debería ser String) ---\")\n",
    "# Verificamos que Polars haya obedecido\n",
    "print(df_raw.schema[\"date\"])\n",
    "display(df_raw.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fc9f960-6bfb-4587-b70d-c1443da3ef5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpiando y tipificando...\n",
      "¡Datos limpios listos!\n",
      "--- Conteo de nulos en la columna 'date' post-conversión ---\n",
      "Total de fechas nulas: 0\n",
      "\n",
      "¡ÉXITO! Todas las fechas se convirtieron correctamente.\n",
      "\n",
      "--- Esquema final de df_clean (la columna 'date' debe ser 'Date') ---\n",
      "Schema({'route_id': Int64, 'date': Date, 'driver_id': Int64, 'origin_barrio': String, 'barrios_recorridos': String, 'tipo_vehiculo': String, 'volumen_cargado_m3': Float64, 'carga_pct': Float64, 'n_paradas': Int64, 'n_paquetes': Int64, 'km_total': Float64, 'velocidad_media_kmh': Float64, 'duracion_min': Int64, 'tiempo_conduccion_min': Int64, 'tiempo_paradas_min': Int64, 'porcentaje_entregas_exitosas': Float64, 'clima': String, 'estado_ruta': String, 'n_incidentes': Int64})\n"
     ]
    }
   ],
   "source": [
    "# Celda 3 (MODIFICADA CON DEPURACIÓN)\n",
    "print(\"Limpiando y tipificando...\")\n",
    "\n",
    "df_clean = df_raw.select(\n",
    "    pl.col(\"route_id\").cast(pl.Int64),\n",
    "    \n",
    "    # LÍNEA CORREGIDA:\n",
    "    pl.col(\"date\").str.to_datetime(format=\"%Y-%m-%d %H:%M:%S\", strict=False).cast(pl.Date).alias(\"date\"),\n",
    "    \n",
    "    pl.col(\"driver_id\").cast(pl.Int64),\n",
    "    pl.col(\"origin_barrio\").cast(pl.String),\n",
    "    pl.col(\"barrios_recorridos\").cast(pl.String),\n",
    "    pl.col(\"tipo_vehiculo\").cast(pl.String),\n",
    "    pl.col(\"volumen_cargado_m3\").cast(pl.Float64),\n",
    "    pl.col(\"carga_pct\").cast(pl.Float64),\n",
    "    pl.col(\"n_paradas\").cast(pl.Int64),\n",
    "    pl.col(\"n_paquetes\").cast(pl.Int64),\n",
    "    pl.col(\"km_total\").cast(pl.Float64),\n",
    "    pl.col(\"velocidad_media_kmh\").cast(pl.Float64),\n",
    "    pl.col(\"duracion_min\").cast(pl.Int64),\n",
    "    pl.col(\"tiempo_conduccion_min\").cast(pl.Int64),\n",
    "    pl.col(\"tiempo_paradas_min\").cast(pl.Int64),\n",
    "    pl.col(\"porcentaje_entregas_exitosas\").cast(pl.Float64),\n",
    "    pl.col(\"clima\").cast(pl.String),\n",
    "    pl.col(\"estado_ruta\").cast(pl.String),\n",
    "    pl.col(\"n_incidentes\").cast(pl.Int64)\n",
    ").filter(pl.col(\"route_id\").is_not_null()) # Quitar filas malas\n",
    "\n",
    "# --- CÓDIGO DE DEPURACIÓN INTEGRADO ---\n",
    "print(\"¡Datos limpios listos!\")\n",
    "print(\"--- Conteo de nulos en la columna 'date' post-conversión ---\")\n",
    "\n",
    "# Contamos cuántos nulos hay AHORA en la columna 'date' limpia\n",
    "null_count = df_clean.select(pl.col(\"date\").is_null().sum()).item()\n",
    "print(f\"Total de fechas nulas: {null_count}\")\n",
    "\n",
    "if null_count == len(df_clean):\n",
    "    print(\"\\n¡ERROR DE DEPURACIÓN! TODAS las fechas siguen siendo nulas.\")\n",
    "    print(\"Mostrando 5 filas 'crudas' para ver el formato original:\")\n",
    "    display(df_raw.head(5).select(\"date\"))\n",
    "elif null_count > 0:\n",
    "    print(f\"\\n¡ADVERTENCIA! Se encontraron {null_count} fechas nulas.\")\n",
    "    print(\"Mostrando 5 filas 'crudas' que fallaron la conversión:\")\n",
    "    display(\n",
    "        df_raw.filter(\n",
    "            pl.col(\"date\").str.to_date(format=\"%d/%m/%Y\", strict=False).is_null()\n",
    "        ).head(5).select(\"date\")\n",
    "    )\n",
    "else:\n",
    "    print(\"\\n¡ÉXITO! Todas las fechas se convirtieron correctamente.\")\n",
    "    \n",
    "print(\"\\n--- Esquema final de df_clean (la columna 'date' debe ser 'Date') ---\")\n",
    "print(df_clean.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91980af-5526-4edc-b4da-4b94b6e454c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliente de BigQuery listo. Apuntando a: /projects/logistics-prod-analysis/datasets/logistica_prod/tables/rutas_clean\n"
     ]
    }
   ],
   "source": [
    "# Celda 4: (L)oad - Configurar Cliente de BigQuery\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# El ID de tu proyecto\n",
    "PROJECT_ID = \"logistics-prod-analysis\"\n",
    "# El ID del Dataset (Schema) que queremos crear\n",
    "DATASET_ID = \"logistica_prod\"\n",
    "# El ID de la tabla que queremos crear\n",
    "TABLE_ID = \"rutas_clean\"\n",
    "\n",
    "# La autenticación (gcloud auth login) que hiciste en la terminal \n",
    "# será usada automáticamente por este cliente. ¡Magia!\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "\n",
    "# Define la ruta completa de la tabla\n",
    "table_ref = client.dataset(DATASET_ID).table(TABLE_ID)\n",
    "print(f\"Cliente de BigQuery listo. Apuntando a: {table_ref.path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df777003-fee3-47f4-a794-8aa59936c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset logistica_prod ya existe. ¡Bien!\n"
     ]
    }
   ],
   "source": [
    "# Celda 5: (L)oad - Crear el Dataset (si no existe)\n",
    "# Esto es como 'CREATE SCHEMA' en SQL\n",
    "\n",
    "dataset = bigquery.Dataset(client.dataset(DATASET_ID))\n",
    "dataset.location = \"US\" # (Elige una ubicación de \"always-free\")\n",
    "\n",
    "try:\n",
    "    client.create_dataset(dataset, timeout=30)\n",
    "    print(f\"Dataset {DATASET_ID} creado.\")\n",
    "except Exception as e:\n",
    "    if \"Already Exists\" in str(e):\n",
    "        print(f\"Dataset {DATASET_ID} ya existe. ¡Bien!\")\n",
    "    else:\n",
    "        raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "187e4f8f-5c73-4b88-a297-316d8ee6a76e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando carga de DataFrame a BigQuery...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu-t430/Desktop/gcp-logistics-pipeline/venv/lib/python3.12/site-packages/google/cloud/bigquery/_pandas_helpers.py:484: FutureWarning: Loading pandas DataFrame into BigQuery will require pandas-gbq package version 0.26.1 or greater in the future. Tried to import pandas-gbq and got: No module named 'pandas_gbq'\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trabajo de carga enviado. Esperando a que termine...\n",
      "¡Éxito! 246836 filas cargadas en logistics-prod-analysis.logistica_prod.rutas_clean\n"
     ]
    }
   ],
   "source": [
    "# Celda 6: (L)oad - Cargar el DataFrame a BigQuery\n",
    "# ¡Este es el paso clave!\n",
    "# Convertimos de Polars -> Arrow -> BigQuery (súper rápido)\n",
    "# Si Polars da error, usa .to_pandas()\n",
    "\n",
    "print(\"Iniciando carga de DataFrame a BigQuery...\")\n",
    "# Polars se integra con Arrow, que BigQuery entiende\n",
    "# .to_arrow() es más eficiente que .to_pandas()\n",
    "job_config = bigquery.LoadJobConfig(\n",
    "    # 'WRITE_TRUNCATE' borra la tabla y la recrea. Perfecto para desarrollo.\n",
    "    write_disposition=bigquery.WriteDisposition.WRITE_TRUNCATE,\n",
    ")\n",
    "\n",
    "# ¡La acción!\n",
    "load_job = client.load_table_from_dataframe(\n",
    "    df_clean.to_pandas(), # Usar .to_pandas() es más estable para la librería de BQ\n",
    "    table_ref,\n",
    "    job_config=job_config\n",
    ")\n",
    "\n",
    "print(\"Trabajo de carga enviado. Esperando a que termine...\")\n",
    "load_job.result() # Espera a que el trabajo termine\n",
    "\n",
    "print(f\"¡Éxito! {load_job.output_rows} filas cargadas en {PROJECT_ID}.{DATASET_ID}.{TABLE_ID}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab6f21d6-d1c1-4c17-a70c-ae5a915ff58b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
